{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing necessary libraries "
      ],
      "metadata": {
        "id": "i7fY-SjfHsqC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JIbwVJG3iCjR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting the files"
      ],
      "metadata": {
        "id": "9DdrCwhcH1CO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_a=pd.read_csv(\"5_a.csv\")\n",
        "df_b=pd.read_csv(\"5_b.csv\")\n",
        "df_c=pd.read_csv(\"5_c.csv\")\n",
        "df_d=pd.read_csv(\"5_d.csv\")"
      ],
      "metadata": {
        "id": "UaIEmR_9pTlY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probability Value --> Output Label "
      ],
      "metadata": {
        "id": "yewh5o4HINRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_a['y_pred']=df_a['proba'].apply(lambda x: 1 if x>=.5 else 0)\n",
        "df_b['y_pred']=df_b['proba'].apply(lambda x: 1 if x>=.5 else 0)"
      ],
      "metadata": {
        "id": "a4GJD7gApjoN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix "
      ],
      "metadata": {
        "id": "Vi2zVCAKJqCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def confusion_matrix(data):\n",
        "    count_tn=len(data[(data['y']==0) & (data['y_pred']==0)])\n",
        "    count_tp=len(data[(data['y']==1) & (data['y_pred']==1)]) \n",
        "    count_fn=len(data[(data['y']==1) & (data['y_pred']==0)])\n",
        "    count_fp=len(data[(data['y']==0) & (data['y_pred']==1)])\n",
        "    return count_fn,count_fp,count_tn,count_tp"
      ],
      "metadata": {
        "id": "Q8Ow8IlQxFql"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the F1 Score \n"
      ],
      "metadata": {
        "id": "ASOT3h2HJt6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_score(data):\n",
        "    fn,fp,tn,tp=confusion_matrix(data)\n",
        "    precision=tp/(tp+fp)                   \n",
        "    recall=tp/(tp+fn)                    \n",
        "    f1=2*((precision*recall)/(precision+recall))\n",
        "    return f1"
      ],
      "metadata": {
        "id": "3bcEJ0YTBjwZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating Accuracy Level"
      ],
      "metadata": {
        "id": "qmBDlrYnKLVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(data):\n",
        "    fn,fp,tn,tp=confusion_matrix(data)\n",
        "    acc=((tp+tn)/(tp+fp+fn+tn))          \n",
        "    return acc"
      ],
      "metadata": {
        "id": "m3sr_OXkCjRG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The AUC Value \n"
      ],
      "metadata": {
        "id": "tN68mX5TKTJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def auc_score(data):\n",
        "    tpr_array=[]\n",
        "    fpr_array=[]\n",
        "    sort= data.sort_values(\"proba\",ascending=False) \n",
        "    for i in range(0,len(sort)):\n",
        "        sort['y_pred']=np.where(sort['proba']>=sort.iloc[i]['proba'],1,0) \n",
        "        FN,FP,TN,TP=confusion_matrix(sort)    \n",
        "        fpr_rate=FP/(TN+FP)\n",
        "        tpr_rate=TP/(TP+FN)\n",
        "        tpr_array.append(tpr_rate)\n",
        "        fpr_array.append(fpr_rate)\n",
        "    c=np.trapz(tpr_array, fpr_array)\n",
        "    return c"
      ],
      "metadata": {
        "id": "TFWAKl8OCj0Q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PERFORMANCE MATRIX FOR 5_a.csv**"
      ],
      "metadata": {
        "id": "9hhBpxWTKVok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix 5_a.csv"
      ],
      "metadata": {
        "id": "E7bZtwKhaCy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FN,FP,TN,TP=confusion_matrix(df_a)\n",
        "print(\"False Negative --> \",FN)\n",
        "print(\"False Positive --> \",FP)\n",
        "print(\"True Negative  --> \",TN)\n",
        "print(\"True Positive  --> \",TP)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1sJIdZZDYpU",
        "outputId": "5015db96-0aa3-4709-d9e1-ce8b10063dbe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False Negative -->  0\n",
            "False Positive -->  100\n",
            "True Negative  -->  0\n",
            "True Positive  -->  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "f1 Score 5_a.csv , Accuracy Value 5_a.csv , AUC Value 5_a.csv"
      ],
      "metadata": {
        "id": "MPUT21dTbKmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1=f1_score(df_a)\n",
        "print(\"f1 Score:\",f1)\n",
        "\n",
        "print(\"------------------\")\n",
        "\n",
        "acc=accuracy(df_a)\n",
        "print('Accuracy Value :',acc)\n",
        "\n",
        "\n",
        "print(\"------------------\")\n",
        "\n",
        "auc=auc_score(df_a)\n",
        "print('AUC Value :',auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqOTxiEJDZVi",
        "outputId": "16e9ed85-f994-4da1-e878-b54b206ec8ce"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 Score: 0.9950248756218906\n",
            "------------------\n",
            "Accuracy Value : 0.9900990099009901\n",
            "------------------\n",
            "AUC Value : 0.48829900000000004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix 5_b.csv"
      ],
      "metadata": {
        "id": "O_8Cx2oRdUKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FN,FP,TN,TP=confusion_matrix(df_b)\n",
        "print(\"False Negative --> \",FN)\n",
        "print(\"False Positive --> \",FP)\n",
        "print(\"True Negative  --> \",TN)\n",
        "print(\"True Positive  --> \",TP)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNSd6JOdEoXM",
        "outputId": "d4f0f9ff-fbf1-41ce-e54e-87ace7a62a3b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False Negative -->  45\n",
            "False Positive -->  239\n",
            "True Negative  -->  9761\n",
            "True Positive  -->  55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "f1 Score 5_b.csv"
      ],
      "metadata": {
        "id": "vbkRFvcwdgv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1=f1_score(df_b)\n",
        "print(\"f1 Score :\",f1)\n",
        "\n",
        "print(\"-----------\")\n",
        "\n",
        "acc=accuracy(df_b)\n",
        "print('Accuracy Level :',acc)\n",
        "\n",
        "print(\"-----------\")\n",
        "\n",
        "auc=auc_score(df_b)\n",
        "print(\"AUC Value :\",auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy6E5mTDEy58",
        "outputId": "cf954b8a-2b07-49c4-d5ef-12b1d4ae7af2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 Score : 0.2791878172588833\n",
            "-----------\n",
            "Accuracy Level : 0.9718811881188119\n",
            "-----------\n",
            "AUC Value : 0.9377570000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the best threshold of probability which gives lowest values of metric A for the given data 5_c.csv"
      ],
      "metadata": {
        "id": "ZPzqHyrLe_cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def best_threshold(data):\n",
        "    tester=0\n",
        "    threshold=[]\n",
        "    A=[]\n",
        "    sorted= data.sort_values(\"prob\",ascending=False) \n",
        "    for i in range(0,len(sorted)):\n",
        "        if tester==(sorted.iloc[i]['prob']):\n",
        "            continue\n",
        "        tester=sorted.iloc[i]['prob'] \n",
        "        threshold.append(tester)\n",
        "        sorted['y_pred']=np.where(sorted['prob']>=sorted.iloc[i]['prob'],1,0)\n",
        "        FN,FP,TN,TP=confusion_matrix(sorted) \n",
        "        value=500*FN+100*FP\n",
        "        A.append(value)  \n",
        "    index=A.index(min(A)) \n",
        "    return threshold[index]"
      ],
      "metadata": {
        "id": "1nOuVmfYE8oH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best=best_threshold(df_c)\n",
        "print('Best Threshold Value -->',best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaWndin7FPY9",
        "outputId": "dcbfb710-7983-4190-80cd-b8d7e7d9bf38"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold Value --> 0.2300390278970873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute performance metrics(for regression) for the given data 5_d.csv"
      ],
      "metadata": {
        "id": "PJHH3YAUfObp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def regression_metrics(data):\n",
        "    n=len(data)\n",
        "    data['ei']= data.apply(lambda x: abs(x['y'] - x['pred']), axis=1) \n",
        "    data['mse']= data['ei'].apply(lambda x: x*x)\n",
        "    total=data['mse'].sum()\n",
        "    mse=total/n\n",
        "    mape=(data['ei'].sum())/(data['y'].sum())\n",
        "    mean=(data['y'].sum())/n \n",
        "    ssres=data['mse'].sum()\n",
        "    data['sstotal']= data.apply(lambda x: (x['y'] - mean), axis=1)\n",
        "    data['sstotal']= data['sstotal'].apply(lambda x: x*x)\n",
        "    sstotal=data['sstotal'].sum()\n",
        "    rsquared=1-(ssres/sstotal)\n",
        "    return mse,mape,rsquared"
      ],
      "metadata": {
        "id": "LHhRwc_MGbhx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse,mape,rsquared=regression_metrics(df_d)\n",
        "print('Mean Squared  Error -->',mse)\n",
        "print('Mean Absolute % Error -->',mape*100)\n",
        "print('R Squared  -->',rsquared)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5Fr9d1IGeh4",
        "outputId": "938e4f9e-81a3-4cde-cfd9-e5185b026c80"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared  Error --> 177.16569974554707\n",
            "Mean Absolute % Error --> 12.91202994009687\n",
            "R Squared  --> 0.9563582786990937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reference --> Applied AI Videos  + Internet( ML Sites )"
      ],
      "metadata": {
        "id": "R5hKxR0Upfn1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KpL5kf5kqATJ"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}